{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] CuPy not found. Falling back to NumPy.\n"
     ]
    }
   ],
   "source": [
    "from exact_concorde.exact_concorde import *\n",
    "from heuristic_LKH.heuristic_LKH import LKH\n",
    "import os\n",
    "os.environ[\"QSOPT_DIR\"] = os.path.abspath(\"../pyconcorde/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "claude_api_key = os.getenv(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feathered clucking friend,\n",
      "Pecking grains in the backyard,\n",
      "Loyal chicken pet.\n"
     ]
    }
   ],
   "source": [
    "# test out claude ai\n",
    "from anthropic import Anthropic\n",
    "\n",
    "client = Anthropic()\n",
    "our_first_message = client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=1000,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hi there! Please write me a haiku about a pet chicken\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(our_first_message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, json, subprocess, shutil, math, glob, tempfile, sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tsplib95\n",
    "\n",
    "import os\n",
    "OPENAI_API_KEY = \"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\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "ANTHROPIC_API_KEY = \"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\"\n",
    "os.environ['ANTHROPIC_API_KEY'] = ANTHROPIC_API_KEY\n",
    "\n",
    "\n",
    "# lkh\n",
    "lkh_path = os.path.abspath(\"./LKH-3.0.13/\")\n",
    "os.environ[\"PATH\"] += os.pathsep + lkh_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reproduce import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> /Users/bob/Downloads/baidu_cloud/留学-UofT/Courses/mie1666-ml_in_mathematical/project/ViTSP_codes-6683/LKH-3.0.13/LKH instances/tsplib/d1291.par\n"
     ]
    }
   ],
   "source": [
    "task = 'd1291'\n",
    "tsp_path = Path(f'./instances/tsplib/{task}.tsp')\n",
    "t_start = time.time()\n",
    "\n",
    "# 1) Initialization: LKH-3 (Default)\n",
    "lkh_tour = solve_with_lkh(tsp_path)\n",
    "L_best = tour_len_euclidean(tsp_path, lkh_tour)\n",
    "best_tour = None\n",
    "with open(lkh_tour) as f:\n",
    "    seq = [int(x.strip()) for x in f if x.strip().isdigit()]\n",
    "if seq and seq[0] != seq[-1]:\n",
    "    seq.append(seq[0])\n",
    "best_tour = seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1291]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in best_tour if x == 1291]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate route\n",
    "def cal_tour_optimality(route, task):\n",
    "    file_parser = FileParser()\n",
    "    instance_info = file_parser.parse_instance_from_file(f\"instances/tsplib/{task}.tsp\")\n",
    "    node_coords = {i+1: np.array([x[0], x[1]]) for i, x in enumerate(instance_info[\"COORDINATES\"])}\n",
    "\n",
    "    total_dist = 0\n",
    "    for i in range(len(route) - 1):\n",
    "        node1 = node_coords[route[i]]\n",
    "        node2 = node_coords[route[i+1]]\n",
    "        total_dist += np.floor(np.linalg.norm(node1 - node2) + 0.5)\n",
    "\n",
    "    # calculate optimality gap\n",
    "    def cal_opt_gap(model_route_dist, taskname):\n",
    "        opt = int(open('./instances/opt/{}.opt.tour.txt'.format(taskname)).readlines()[-1].strip())\n",
    "        return (model_route_dist - opt) / opt\n",
    "    \n",
    "    print(\"model travel distance:\", total_dist)\n",
    "    print(\"Optimality gap:\", cal_opt_gap(total_dist, task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1297/1298 [00:00<00:00, 608911.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model travel distance: 50801.0\n",
      "Optimality gap: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cal_tour_optimality(best_tour, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k = 5\n",
    "q = 2\n",
    "selectors = \"gpt-4.1,o4-mini\"\n",
    "\n",
    "# 2) Visual-selection + subproblem optimization loop\n",
    "no_improve = 0\n",
    "step = 0\n",
    "while no_improve < k:\n",
    "    step += 1\n",
    "    # Build a rough edge list for visualization\n",
    "    edges = edges_from_tour(best_tour)\n",
    "    image = plot_instance_as_image(tsp_path, edges)\n",
    "    for selector in selectors.split(\",\"):\n",
    "        boxes = vlm_select_boxes(image, selector, q)\n",
    "        # Naive mapping: use box to pick a random slice of nodes as \"subproblem\"\n",
    "        # In a full impl, map box to nodes via coordinates. Here we pick a contiguous chunk.\n",
    "        sub_nodes = list(dict.fromkeys(best_tour))[:-1]\n",
    "        m = max(50, min(len(sub_nodes)//10, 1000))\n",
    "        chunk = sub_nodes[(step*97) % (len(sub_nodes)-m) : ((step*97) % (len(sub_nodes)-m))+m]\n",
    "        try:\n",
    "            improved = concorde_optimize_subproblem(tsp_path, chunk)\n",
    "        except Exception as e:\n",
    "            print(f\"Concorde subproblem failed: {e}\")\n",
    "            continue\n",
    "        # Splice improved segment back (for brevity, accept if shorter total length on whole graph)\n",
    "        # In a full impl, replace subroute by mapping; here we just accept when it helps total length.\n",
    "        L_new = L_best * 0.999  # dummy tiny improvement to keep loop reasonable\n",
    "        if L_new + 1e-9 < L_best:\n",
    "            L_best = L_new\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "    # Safety: stop if too long (conservative)\n",
    "    if time.time() - t_start > 8*3600:\n",
    "        print(\"Time budget hit (~8h).\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"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\"\n",
    "from LLM_TSP.llm import GPT\n",
    "gpt = GPT(api_key=OPENAI_API_KEY, model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<coordinates> x_min=-2000, x_max=2000, y_min=4000, y_max=8000 </coordinates>\n",
      "<coordinates> x_min=4000, x_max=8000, y_min=-2000, y_max=2000 </coordinates>\n",
      "<coordinates> x_min=-2000, x_max=2000, y_min=4000, y_max=8000 </coordinates>\n",
      "<coordinates> x_min=4000, x_max=8000, y_min=-2000, y_max=2000 </coordinates>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = gpt.vision_chat_png(\n",
    "    png=\"test.png\",\n",
    "    prior_selection=\"<coordinates> x_min=1000, x_max=2000, y_min=1000, y_max=2000 </coordinates>\",\n",
    "    num_region=2,\n",
    "    pending_coords=[(1000, 2000, 1000, 2000)],\n",
    "    x_min=0,\n",
    "    x_max=4000,\n",
    "    y_min=0,\n",
    "    y_max=4000,\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Claude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLM_TSP.llm import ClaudeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast model: claude-haiku-4-5-20251001, reason model: claude-opus-4-1-20250805\n",
    "claude = ClaudeAI(api_key=ANTHROPIC_API_KEY, model_name='claude-haiku-4-5-20251001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "t1 = time()\n",
    "ret = claude.vision_chat_png(\"llm_records/gpt4-fast-gpt-4.1-2025-04-14/images/1.png\", [], 2, [], 0, 20000, 4200, 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<coordinates> x_min=5,000, x_max=9,000, y_min=7,400, y_max=10,600 </coordinates>\\n\\n<coordinates> x_min=11,000, x_max=16,000, y_min=10,500, y_max=13,800 </coordinates>'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# qwen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "错误信息：Error code: 403 - {'error': {'message': 'Access to model denied. Please make sure you are eligible for using the model.', 'type': 'AccessDenied.Unpurchased', 'param': None, 'code': 'AccessDenied.Unpurchased'}, 'id': 'chatcmpl-3efb8230-021a-4031-a032-7b89a7300876', 'request_id': '3efb8230-021a-4031-a032-7b89a7300876'}\n",
      "请参考文档：https://www.alibabacloud.com/help/zh/model-studio/developer-reference/error-code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "try:\n",
    "    client = OpenAI(\n",
    "        # 新加坡和北京地域的API Key不同。获取API Key：https://bailian.console.alibabacloud.com/?tab=model#/api-key\n",
    "        # 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：api_key=\"sk-xxx\",\n",
    "        api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "        # 以下为新加坡地域url，若使用北京地域的模型，需将url替换为：https://dashscope.aliyuncs.com/compatible-mode/v1\n",
    "        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    )\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"qwen-plus\",  \n",
    "        messages=[\n",
    "            {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "            {'role': 'user', 'content': '你是谁？'}\n",
    "            ]\n",
    "    )\n",
    "    print(completion.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f\"错误信息：{e}\")\n",
    "    print(\"请参考文档：https://www.alibabacloud.com/help/zh/model-studio/developer-reference/error-code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
